{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is to initialize the pretrained VGG16 model with ImageNet weights and retrain the model from end to end on the current task of detecting Pneumonia and further differentiate Bacterial and Viral Pneumonia types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.models import model_from_json\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from evaluation import plot_confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "train_data_dir = 'cxr_normal_pneumonia_1024/train'\n",
    "test_data_dir = 'cxr_normal_pneumonia_1024/test'\n",
    "img_width = 1024\n",
    "img_height = 1024\n",
    "channel = 3\n",
    "input_img = Input(shape = (img_width, img_height, channel))\n",
    "epochs = 60\n",
    "batch_size = 8 #vary this parameter depending on your GPU capacity\n",
    "num_classes= 2 #[pneumonia, normal] [bacterial, viral]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the VGG16 and customize\n",
    "feature_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width,img_height,channel))\n",
    "feature_model=Model(inputs=feature_model.input,outputs=feature_model.get_layer('block5_conv3').output)\n",
    "\n",
    "#addind the top layers\n",
    "x = feature_model.output\n",
    "x = GlobalAveragePooling2D()(x) \n",
    "predictions = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "model = Model(inputs=feature_model.input, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "#plot the model\n",
    "plot_model(model, to_file='custom_VGG16_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed five-fold cross validation in this study. We have however shown running the script with a sample data fold. We performed no augmentation other than rescaling.We allocated 20% of the training data at random for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring image data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2) #taking 20% of training for validation \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(1024, 1024),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(1024, 1024),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(1024, 1024),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',shuffle=False)\n",
    "\n",
    "#count the number of samples\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "nb_test_samples = len(test_generator.filenames)\n",
    "\n",
    "#check the class indices\n",
    "train_generator.class_indices\n",
    "validation_generator.class_indices\n",
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocate balanced weights to penalize over-represented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_generator.classes), \n",
    "                train_generator.classes)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the optimizer\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True) #optimize to your requirements\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#compute the training time\n",
    "start = time.time()\n",
    "\n",
    "#give the path to store the model weights\n",
    "filepath = 'weights/' + model.name + '.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
    "\n",
    "#save only the best weights\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_weights_only=True, save_best_only=True, mode='max', period=1)\n",
    "\n",
    "#visualize model performance using TensorBoard\n",
    "tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=batch_size)\n",
    "callbacks_list = [checkpoint, tensor_board]\n",
    "\n",
    "#train model\n",
    "custom_vgg16_history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=nb_train_samples // batch_size, \n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator,\n",
    "      callbacks=callbacks_list,\n",
    "      class_weight = class_weights,\n",
    "      validation_steps=nb_validation_samples // batch_size, \n",
    "      verbose=1)\n",
    "\n",
    "#print the total time taken for training\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model's performance by loading the model weights\n",
    "\n",
    "model.load_weights('weights/weights-improvement-39-0.9615.hdf5') #change this to your path and model weights\n",
    "custom_vgg16_y_pred = model.predict_generator(test_generator, nb_test_samples/batch_size, workers=1)\n",
    "\n",
    "#true labels\n",
    "Y_test=test_generator.classes\n",
    "\n",
    "#print the shape of y_pred and Y_test\n",
    "print(custom_vgg16_y_pred.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#measure accuracy\n",
    "custom_vgg16_model_accuracy=accuracy_score(Y_test,custom_vgg16_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of custom VGG16 model is: ', custom_vgg16_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "target_names = ['class 0(normal)', 'class 1(pneumonia)'] #from the generator.class_indices\n",
    "print(classification_report(Y_test,custom_vgg16_y_pred.argmax(axis=-1),\n",
    "                                                              target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,custom_vgg16_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "plt.figure(figsize=(20,10), dpi=100)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
    "                      title='Confusion matrix for custom VGG16 model without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the predictions in .csv files\n",
    "print(custom_vgg16_y_pred.argmax(axis=-1))\n",
    "print(Y_test)\n",
    "\n",
    "np.savetxt('custom_VGG16_y_pred.csv',custom_vgg16_y_pred.argmax(axis=-1),fmt='%i',delimiter = \",\")\n",
    "np.savetxt('Y_test.csv',Y_test,fmt='%i',delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, custom_vgg16_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(15,10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.10)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.10)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristics')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
